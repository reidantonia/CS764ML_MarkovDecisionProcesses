# CS7641 Assignment 4: My Exploration of Markov Decision Processes

## Overview
The assignment aims to extend our understanding of machine learning, specifically focusing on applying reinforcement learning techniques for decision-making. This involves a hands-on exploration of Markov Decision Processes (MDPs) and their practical applications in enabling an agent to interact more directly with the world.


## Algorithms Explored
1. Value-Iteration
2. Policy Iteration
3. Q-Learning

## Getting Started & Prerequisites
To replicate these experiments on your own machine, you'll need to have Python 3.8 installed along with the following essential packages:

- numpy
- matplotlib.pyplot
- hiive.mdptoolbox
- seaborn
- gym
- generate_random_map
- random
- time

## Instructions for Running the Experiments
Each of these files generates a set of insightful graphs and results pertaining to the algorithm's performance. 

## Running the Experiments
To execute the experiments for both sets of environments, follow these steps:

### Forest Environment
The Forest environment's default settings involve forests of size 500 and 1000. Run the following Python files:

- Forest_PolicyIteration.py
- Forest_ValueIteration.py
- Forest_QLearning.py

### Frozen Lake Environment
By default, the experiments are configured for the FrozenLake environment with sizes 5 and 20. Execute the following Python files:

- FrozenLake_PolicyIteration.py
- FrozenLake_ValueIteration.py
- FrozenLake_QLearning.py

Once you run each of these files, the output images will be saved in the "Images" subdirectory for your reference and analysis. Dive into the results to gain valuable insights into how these algorithms perform in different environments and under varying conditions.

Link to repository: https://drive.google.com/drive/folders/1AtaEmYvNYDeNjXPhvwf1G8EJg5As2EfK?usp=sharing